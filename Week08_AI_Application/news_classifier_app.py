"""
Week 08: AI ì‘ìš© í”„ë¡œì íŠ¸ - ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ì‹œìŠ¤í…œ
Streamlitì„ ì´ìš©í•œ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜
"""

import streamlit as st
import pandas as pd
import numpy as np
import pickle
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline
import re
from datetime import datetime

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ê¸°",
    page_icon="ğŸ“°",
    layout="wide"
)

# ì œëª©
st.title("ğŸ“° ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ ìë™ ë¶„ë¥˜ ì‹œìŠ¤í…œ")
st.markdown("---")

# ì‚¬ì´ë“œë°”
st.sidebar.title("ğŸ”§ ì„¤ì •")
st.sidebar.markdown("### í”„ë¡œì íŠ¸ ì •ë³´")
st.sidebar.info("""
**Week 8 AI ì‘ìš© í”„ë¡œì íŠ¸**
- ë‰´ìŠ¤ ê¸°ì‚¬ ìë™ ë¶„ë¥˜
- ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ í…ìŠ¤íŠ¸ ë¶„ë¥˜
- ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹œìŠ¤í…œ
""")

# í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ í•¨ìˆ˜
@st.cache_data
def preprocess_text(text):
    """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬"""
    # íŠ¹ìˆ˜ë¬¸ì ì œê±°
    text = re.sub(r'[^ê°€-í£ã„±-ã…ã…-ã…£a-zA-Z0-9\s]', '', text)
    # ì—°ì† ê³µë°± ì œê±°
    text = re.sub(r'\s+', ' ', text)
    # ì•ë’¤ ê³µë°± ì œê±°
    text = text.strip()
    return text

# ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜ (ë°ëª¨ìš©)
@st.cache_resource
def train_demo_model():
    """ë°ëª¨ìš© ë‰´ìŠ¤ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ"""
    
    # ìƒ˜í”Œ ë‰´ìŠ¤ ë°ì´í„°
    news_data = {
        'content': [
            # ì •ì¹˜
            "ëŒ€í†µë ¹ì´ ì˜¤ëŠ˜ êµ­ì •í˜„ì•ˆì— ëŒ€í•œ ë‹´í™”ë¥¼ ë°œí‘œí–ˆìŠµë‹ˆë‹¤. ê²½ì œì •ì±…ê³¼ ì™¸êµì •ì±…ì— ëŒ€í•œ í–¥í›„ ê³„íšì„ ì„¤ëª…í–ˆìŠµë‹ˆë‹¤.",
            "êµ­íšŒì—ì„œ ì˜ˆì‚°ì•ˆ ì‹¬ì˜ê°€ ì§„í–‰ë˜ê³  ìˆìŠµë‹ˆë‹¤. ì—¬ì•¼ ê°„ ì´ê²¬ì´ íŒ½íŒ½í•œ ìƒí™©ì…ë‹ˆë‹¤.",
            "ì •ë¶€ê°€ ìƒˆë¡œìš´ ì •ì±…ì„ ë°œí‘œí–ˆìŠµë‹ˆë‹¤. êµ­ë¯¼ë“¤ì˜ ê´€ì‹¬ì´ ì§‘ì¤‘ë˜ê³  ìˆìŠµë‹ˆë‹¤.",
            "ì„ ê±° ì¤€ë¹„ê°€ ë³¸ê²©í™”ë˜ê³  ìˆìŠµë‹ˆë‹¤. ê° ì •ë‹¹ì˜ ê³µì•½ ë°œí‘œê°€ ì´ì–´ì§€ê³  ìˆìŠµë‹ˆë‹¤.",
            
            # ê²½ì œ
            "ì£¼ì‹ì‹œì¥ì´ ìƒìŠ¹ì„¸ë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤. íˆ¬ììë“¤ì˜ ê´€ì‹¬ì´ ë†’ì•„ì§€ê³  ìˆìŠµë‹ˆë‹¤.",
            "ì¤‘ì•™ì€í–‰ì´ ê¸°ì¤€ê¸ˆë¦¬ë¥¼ ì¡°ì •í–ˆìŠµë‹ˆë‹¤. ì‹œì¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì´ ì£¼ëª©ë©ë‹ˆë‹¤.",
            "ëŒ€ê¸°ì—…ì˜ ì‹¤ì  ë°œí‘œê°€ ìˆì—ˆìŠµë‹ˆë‹¤. ë§¤ì¶œê³¼ ìˆœì´ìµì´ í¬ê²Œ ì¦ê°€í–ˆìŠµë‹ˆë‹¤.",
            "ë¶€ë™ì‚° ê°€ê²© ë³€ë™ì— ëŒ€í•œ ë¶„ì„ì´ ë°œí‘œë˜ì—ˆìŠµë‹ˆë‹¤. ì „ë¬¸ê°€ë“¤ì˜ ì˜ê²¬ì´ ë¶„ë¶„í•©ë‹ˆë‹¤.",
            
            # ì‚¬íšŒ
            "êµìœ¡ì •ì±… ê°œí¸ì•ˆì´ ë°œí‘œë˜ì—ˆìŠµë‹ˆë‹¤. í•™ìƒê³¼ í•™ë¶€ëª¨ë“¤ì˜ ë°˜ì‘ì´ ë‹¤ì–‘í•©ë‹ˆë‹¤.",
            "ì˜ë£Œì§„ íŒŒì—…ì´ ê³„ì†ë˜ê³  ìˆìŠµë‹ˆë‹¤. í™˜ìë“¤ì˜ ë¶ˆí¸ì´ ê°€ì¤‘ë˜ê³  ìˆìŠµë‹ˆë‹¤.",
            "ë²”ì£„ ì˜ˆë°©ì„ ìœ„í•œ ìƒˆë¡œìš´ ì‹œìŠ¤í…œì´ ë„ì…ë©ë‹ˆë‹¤. ì‹œë¯¼ë“¤ì˜ ì•ˆì „ í™•ë³´ê°€ ëª©í‘œì…ë‹ˆë‹¤.",
            "ì‚¬íšŒë³µì§€ ì œë„ ê°œì„ ë°©ì•ˆì´ ë…¼ì˜ë˜ê³  ìˆìŠµë‹ˆë‹¤. ì·¨ì•½ê³„ì¸µ ì§€ì›ì´ ê°•í™”ë  ì˜ˆì •ì…ë‹ˆë‹¤.",
            
            # ìŠ¤í¬ì¸ 
            "ì›”ë“œì»µ ì˜ˆì„ ì „ì—ì„œ ìš°ë¦¬ë‚˜ë¼ê°€ ìŠ¹ë¦¬í–ˆìŠµë‹ˆë‹¤. ì„ ìˆ˜ë“¤ì˜ í™œì•½ì´ ë‹ë³´ì˜€ìŠµë‹ˆë‹¤.",
            "í”„ë¡œì•¼êµ¬ ì‹œì¦Œì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. íŒ¬ë“¤ì˜ ê¸°ëŒ€ê°€ ë†’ì•„ì§€ê³  ìˆìŠµë‹ˆë‹¤.",
            "ì˜¬ë¦¼í”½ ì¤€ë¹„ê°€ í•œì°½ì…ë‹ˆë‹¤. ì„ ìˆ˜ë“¤ì˜ í›ˆë ¨ì´ ê°•í™”ë˜ê³  ìˆìŠµë‹ˆë‹¤.",
            "í”„ë¡œì¶•êµ¬ ë¦¬ê·¸ì—ì„œ í¥ë¯¸ì§„ì§„í•œ ê²½ê¸°ê°€ í¼ì³ì¡ŒìŠµë‹ˆë‹¤. ê´€ì¤‘ë“¤ì˜ ì—´ë¤ ì‘ì›ì´ ì´ì–´ì¡ŒìŠµë‹ˆë‹¤.",
            
            # ê¸°ìˆ 
            "ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì´ ë¹ ë¥´ê²Œ ë°œì „í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤.",
            "ìƒˆë¡œìš´ ìŠ¤ë§ˆíŠ¸í°ì´ ì¶œì‹œë˜ì—ˆìŠµë‹ˆë‹¤. í˜ì‹ ì ì¸ ê¸°ëŠ¥ë“¤ì´ íƒ‘ì¬ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "ììœ¨ì£¼í–‰ì°¨ ê¸°ìˆ ì´ ìƒìš©í™” ë‹¨ê³„ì— ì ‘ì–´ë“¤ì—ˆìŠµë‹ˆë‹¤. êµí†µ í˜ì‹ ì´ ê¸°ëŒ€ë©ë‹ˆë‹¤.",
            "ë¸”ë¡ì²´ì¸ ê¸°ìˆ ì˜ í™œìš© ë²”ìœ„ê°€ í™•ëŒ€ë˜ê³  ìˆìŠµë‹ˆë‹¤. ê¸ˆìœµê¶Œì˜ ê´€ì‹¬ì´ ë†’ìŠµë‹ˆë‹¤."
        ],
        'category': [
            'ì •ì¹˜', 'ì •ì¹˜', 'ì •ì¹˜', 'ì •ì¹˜',
            'ê²½ì œ', 'ê²½ì œ', 'ê²½ì œ', 'ê²½ì œ', 
            'ì‚¬íšŒ', 'ì‚¬íšŒ', 'ì‚¬íšŒ', 'ì‚¬íšŒ',
            'ìŠ¤í¬ì¸ ', 'ìŠ¤í¬ì¸ ', 'ìŠ¤í¬ì¸ ', 'ìŠ¤í¬ì¸ ',
            'ê¸°ìˆ ', 'ê¸°ìˆ ', 'ê¸°ìˆ ', 'ê¸°ìˆ '
        ]
    }
    
    df = pd.DataFrame(news_data)
    
    # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
    df['processed_content'] = df['content'].apply(preprocess_text)
    
    # íŒŒì´í”„ë¼ì¸ ìƒì„±
    pipeline = Pipeline([
        ('tfidf', TfidfVectorizer(max_features=1000, stop_words=None)),
        ('classifier', MultinomialNB(alpha=1.0))
    ])
    
    # ëª¨ë¸ í•™ìŠµ
    pipeline.fit(df['processed_content'], df['category'])
    
    return pipeline, df

# ëª¨ë¸ ë¡œë“œ
model, sample_data = train_demo_model()

# ë©”ì¸ ì»¨í…ì¸ 
col1, col2 = st.columns([2, 1])

with col1:
    st.header("ğŸ” ë‰´ìŠ¤ ê¸°ì‚¬ ë¶„ë¥˜")
    
    # í…ìŠ¤íŠ¸ ì…ë ¥
    news_text = st.text_area(
        "ë¶„ë¥˜í•˜ê³  ì‹¶ì€ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”:",
        height=200,
        placeholder="ì˜ˆ: ëŒ€í†µë ¹ì´ ì˜¤ëŠ˜ ìƒˆë¡œìš´ ê²½ì œì •ì±…ì„ ë°œí‘œí–ˆìŠµë‹ˆë‹¤..."
    )
    
    # ì˜ˆì‹œ ë‰´ìŠ¤ ì„ íƒ
    st.subheader("ğŸ“„ ì˜ˆì‹œ ë‰´ìŠ¤ ì„ íƒ")
    selected_example = st.selectbox(
        "ì˜ˆì‹œ ë‰´ìŠ¤ë¥¼ ì„ íƒí•˜ê±°ë‚˜ ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”:",
        ["ì§ì ‘ ì…ë ¥"] + list(sample_data['content'][:10])
    )
    
    if selected_example != "ì§ì ‘ ì…ë ¥":
        news_text = selected_example
        st.text_area("ì„ íƒëœ ë‰´ìŠ¤:", value=news_text, height=100, disabled=True)

with col2:
    st.header("ğŸ“Š ëª¨ë¸ ì •ë³´")
    
    st.metric("í›ˆë ¨ ë°ì´í„° ìˆ˜", len(sample_data))
    st.metric("ì¹´í…Œê³ ë¦¬ ìˆ˜", len(sample_data['category'].unique()))
    
    st.subheader("ğŸ“ ì§€ì› ì¹´í…Œê³ ë¦¬")
    categories = sample_data['category'].unique()
    for cat in categories:
        count = len(sample_data[sample_data['category'] == cat])
        st.write(f"â€¢ {cat}: {count}ê°œ")

# ë¶„ë¥˜ ì‹¤í–‰
if st.button("ğŸš€ ë‰´ìŠ¤ ë¶„ë¥˜í•˜ê¸°", type="primary", use_container_width=True):
    if news_text.strip():
        with st.spinner("ë¶„ë¥˜ ì¤‘..."):
            # ì „ì²˜ë¦¬
            processed_text = preprocess_text(news_text)
            
            # ì˜ˆì¸¡
            prediction = model.predict([processed_text])[0]
            probabilities = model.predict_proba([processed_text])[0]
            
            # ê²°ê³¼ í‘œì‹œ
            st.success("ë¶„ë¥˜ ì™„ë£Œ!")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("ğŸ¯ ì˜ˆì¸¡ ê²°ê³¼")
                st.metric(
                    label="ì¹´í…Œê³ ë¦¬",
                    value=prediction,
                    delta=f"í™•ì‹ ë„: {probabilities.max():.1%}"
                )
            
            with col2:
                st.subheader("ğŸ“Š ì¹´í…Œê³ ë¦¬ë³„ í™•ë¥ ")
                prob_df = pd.DataFrame({
                    'ì¹´í…Œê³ ë¦¬': model.classes_,
                    'í™•ë¥ ': probabilities
                }).sort_values('í™•ë¥ ', ascending=False)
                
                st.dataframe(prob_df, use_container_width=True)
            
            # í™•ë¥  ì‹œê°í™”
            st.subheader("ğŸ“ˆ í™•ë¥  ë¶„í¬")
            chart_data = prob_df.set_index('ì¹´í…Œê³ ë¦¬')
            st.bar_chart(chart_data)
            
            # ë¶„ì„ ê²°ê³¼ ì €ì¥ (ì„¸ì…˜ ìƒíƒœ)
            if 'history' not in st.session_state:
                st.session_state.history = []
            
            st.session_state.history.append({
                'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'text': news_text[:100] + "..." if len(news_text) > 100 else news_text,
                'prediction': prediction,
                'confidence': probabilities.max()
            })
    else:
        st.error("ë‰´ìŠ¤ ê¸°ì‚¬ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!")

# ë¶„ì„ íˆìŠ¤í† ë¦¬
if 'history' in st.session_state and st.session_state.history:
    st.header("ğŸ“‹ ë¶„ì„ íˆìŠ¤í† ë¦¬")
    
    history_df = pd.DataFrame(st.session_state.history)
    
    # ìµœê·¼ 10ê°œë§Œ í‘œì‹œ
    recent_history = history_df.tail(10)
    
    for i, row in recent_history.iterrows():
        with st.expander(f"{row['timestamp']} - {row['prediction']} ({row['confidence']:.1%})"):
            st.write(row['text'])
    
    # íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™” ë²„íŠ¼
    if st.button("ğŸ—‘ï¸ íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”"):
        st.session_state.history = []
        st.rerun()

# í†µê³„ ëŒ€ì‹œë³´ë“œ
st.header("ğŸ“Š ë¶„ì„ í†µê³„")

if 'history' in st.session_state and st.session_state.history:
    history_df = pd.DataFrame(st.session_state.history)
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("ì´ ë¶„ì„ ìˆ˜", len(history_df))
    
    with col2:
        avg_confidence = history_df['confidence'].mean()
        st.metric("í‰ê·  í™•ì‹ ë„", f"{avg_confidence:.1%}")
    
    with col3:
        most_common = history_df['prediction'].mode().iloc[0] if len(history_df) > 0 else "ì—†ìŒ"
        st.metric("ê°€ì¥ ë§ì€ ì¹´í…Œê³ ë¦¬", most_common)
    
    # ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬
    if len(history_df) > 0:
        category_counts = history_df['prediction'].value_counts()
        st.subheader("ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„ í˜„í™©")
        st.bar_chart(category_counts)

# í‘¸í„°
st.markdown("---")
st.markdown("""
<div style='text-align: center'>
    <p>ğŸ¤– <strong>AI ë‰´ìŠ¤ ë¶„ë¥˜ ì‹œìŠ¤í…œ</strong> | Week 8 ë©˜í† ë§ í”„ë¡œì íŠ¸</p>
    <p>ë¨¸ì‹ ëŸ¬ë‹ì„ í™œìš©í•œ í…ìŠ¤íŠ¸ ë¶„ë¥˜ ë°ëª¨</p>
</div>
""", unsafe_allow_html=True)

# ì‚¬ì´ë“œë°” ì¶”ê°€ ì •ë³´
st.sidebar.markdown("---")
st.sidebar.markdown("### ğŸ“š í•™ìŠµ ë‚´ìš©")
st.sidebar.markdown("""
- í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
- TF-IDF ë²¡í„°í™”
- ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ ë¶„ë¥˜
- Streamlit ì›¹ì•± ê°œë°œ
""")

st.sidebar.markdown("### ğŸ”— ë‹¤ìŒ ë‹¨ê³„")
st.sidebar.markdown("""
1. ë” ë§ì€ ë°ì´í„° ìˆ˜ì§‘
2. ë”¥ëŸ¬ë‹ ëª¨ë¸ ì ìš©
3. ì‹¤ì‹œê°„ ë‰´ìŠ¤ í¬ë¡¤ë§
4. ëª¨ë¸ ì„±ëŠ¥ ê°œì„ 
""")
